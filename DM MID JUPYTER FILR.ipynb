{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "47c391f5-0ece-47d2-bd8f-543ba08fba45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlxtend in c:\\users\\rushmitha k\\anaconda3\\lib\\site-packages (0.23.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\rushmitha k\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\rushmitha k\\anaconda3\\lib\\site-packages (from mlxtend) (1.13.1)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\rushmitha k\\anaconda3\\lib\\site-packages (from mlxtend) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn>=1.3.1 in c:\\users\\rushmitha k\\anaconda3\\lib\\site-packages (from mlxtend) (1.4.2)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\rushmitha k\\anaconda3\\lib\\site-packages (from mlxtend) (3.8.4)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\rushmitha k\\anaconda3\\lib\\site-packages (from mlxtend) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rushmitha k\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rushmitha k\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rushmitha k\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\rushmitha k\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\rushmitha k\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\rushmitha k\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\rushmitha k\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rushmitha k\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\rushmitha k\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\rushmitha k\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rushmitha k\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\rushmitha k\\anaconda3\\lib\\site-packages (from scikit-learn>=1.3.1->mlxtend) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mlxtend pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "266f16bb-db17-4130-8359-2d75cfba44e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import time\n",
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, fpgrowth, association_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be48e1bc-c3d0-486a-8531-3be5bce6943a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate support for an itemset.\n",
    "\n",
    "def calculate_support(transactions, itemset):\n",
    "    return sum(1 for transaction in transactions if set(itemset).issubset(set(transaction))) / len(transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "77b71d83-104c-4fc4-8a42-477fe98688fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brute Force algorithm to generate frequent itemset.\n",
    "def brute_force_frequent_itemsets(transactions, min_support):\n",
    "    items = sorted(set(item for transaction in transactions for item in transaction)) # get the unique items from the transactions.\n",
    "    frequent_itemsets = []\n",
    "    itemset_size = 1\n",
    "    \n",
    "    while True:\n",
    "        candidate_itemsets = list(itertools.combinations(items, itemset_size))     # Generate all combinations of itemset from current size.  \n",
    "        current_frequent_itemsets = []\n",
    "        \n",
    "        for itemset in candidate_itemsets:\n",
    "            support = calculate_support(transactions, itemset)\n",
    "            if support >= min_support:\n",
    "                current_frequent_itemsets.append((itemset, support))\n",
    "        \n",
    "        if not current_frequent_itemsets:\n",
    "            break\n",
    "        \n",
    "        frequent_itemsets.extend(current_frequent_itemsets)\n",
    "        itemset_size += 1\n",
    "\n",
    "    return frequent_itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8c72dd77-1e04-499d-bd18-e9eef4cbd3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_association_rules(frequent_itemsets, transactions, min_confidence):\n",
    "    rules = []\n",
    "    for itemset, itemset_support in frequent_itemsets:\n",
    "        if len(itemset) > 1:\n",
    "            for i in range(1, len(itemset)):\n",
    "                for antecedent in itertools.combinations(itemset, i):\n",
    "                    consequent = tuple(item for item in itemset if item not in antecedent)\n",
    "                    antecedent_support = calculate_support(transactions, antecedent)\n",
    "                    confidence = itemset_support / antecedent_support\n",
    "                    if confidence >= min_confidence:\n",
    "                        rules.append((antecedent, consequent, confidence, itemset_support))\n",
    "    return rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1866a7-0325-4263-ae13-ca46ef4ee832",
   "metadata": {},
   "source": [
    "Prepare Transaction DataFrame Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e417e1ed-c348-4e48-af45-9e85b053a993",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_transaction_df(transactions):\n",
    "    items = sorted(set(item for transaction in transactions for item in transaction))\n",
    "    return pd.DataFrame([[item in transaction for item in items] for transaction in transactions], columns=items).astype(bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5507dff0-a024-4f3e-9673-c8b17c331645",
   "metadata": {},
   "source": [
    "Run All Algorithms Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cac7f2f1-e9e3-4b35-912b-2b353e8ac71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_algorithms(transactions, min_support, min_confidence):\n",
    "    transaction_df = prepare_transaction_df(transactions)\n",
    "\n",
    "    # Brute force algorithm\n",
    "    print(\"\\nRunning Brute Force Algorithm...\")\n",
    "    start_time = time.time()\n",
    "    frequent_itemsets_brute = brute_force_frequent_itemsets(transactions, min_support)\n",
    "    rules_brute = generate_association_rules(frequent_itemsets_brute, transactions, min_confidence)\n",
    "    brute_time = time.time() - start_time\n",
    "    print(f\"Brute Force Time: {brute_time:.4f} seconds\")\n",
    "    print_results(\"Brute Force\", frequent_itemsets_brute, rules_brute)\n",
    "\n",
    "    # Apriori Algorithm\n",
    "    print(\"\\nRunning Apriori Algorithm...\")\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        frequent_itemsets_apriori = apriori(transaction_df, min_support=min_support, use_colnames=True)\n",
    "        apriori_time = time.time() - start_time\n",
    "        \n",
    "        if frequent_itemsets_apriori.empty:\n",
    "            print(\"Apriori did not find any frequent itemsets.\")\n",
    "        else:\n",
    "            rules_apriori = association_rules(frequent_itemsets_apriori, metric=\"confidence\", min_threshold=min_confidence)\n",
    "            print(f\"Apriori Time: {apriori_time:.4f} seconds\")\n",
    "            print_results(\"Apriori\", frequent_itemsets_apriori, rules_apriori)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during Apriori algorithm execution: {e}\")\n",
    "        apriori_time = time.time() - start_time\n",
    "\n",
    "    # FP-Growth Algorithm\n",
    "    print(\"\\nRunning FP-Growth Algorithm...\")\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        frequent_itemsets_fpgrowth = fpgrowth(transaction_df, min_support=min_support, use_colnames=True)\n",
    "        fpgrowth_time = time.time() - start_time\n",
    "        \n",
    "        if frequent_itemsets_fpgrowth.empty:\n",
    "            print(\"FP-Growth did not find any frequent itemsets.\")\n",
    "        else:\n",
    "            rules_fpgrowth = association_rules(frequent_itemsets_fpgrowth, metric=\"confidence\", min_threshold=min_confidence)\n",
    "            print(f\"FP-Growth Time: {fpgrowth_time:.4f} seconds\")\n",
    "            print_results(\"FP-Growth\", frequent_itemsets_fpgrowth, rules_fpgrowth)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during FP-Growth algorithm execution: {e}\")\n",
    "        fpgrowth_time = time.time() - start_time\n",
    "    \n",
    "    return brute_time, apriori_time, fpgrowth_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bd53f56a-0ad1-4ce3-a467-902bca1925b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_and_prepare_transactions(transaction_file, itemset_file):\n",
    "    try:\n",
    "        df_trans = pd.read_csv(transaction_file)\n",
    "        df_items = pd.read_csv(itemset_file)\n",
    "        \n",
    "        if 'Item #' in df_items.columns and 'Item Name' in df_items.columns:\n",
    "            item_map = dict(zip(df_items['Item #'], df_items['Item Name']))\n",
    "        else:\n",
    "            item_map = None\n",
    "        \n",
    "        transactions = []\n",
    "        for _, row in df_trans.iterrows():\n",
    "            transaction = []\n",
    "            for item in row:\n",
    "                if isinstance(item, str):\n",
    "                    items = [i.strip() for i in item.split(',') if i.strip()]\n",
    "                    transaction.extend(items)\n",
    "                elif pd.notna(item):\n",
    "                    transaction.append(str(item))\n",
    "            if transaction:\n",
    "                transactions.append(transaction)\n",
    "        \n",
    "        return transactions\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading the CSV files: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ce6ac7ce-0480-45a7-b971-a2d9d25fd5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(algorithm_name, frequent_itemsets, rules):\n",
    "    print(f\"\\n{algorithm_name} Results:\")\n",
    "    print(\"Frequent Itemsets:\")\n",
    "    if isinstance(frequent_itemsets, pd.DataFrame):\n",
    "        for _, row in frequent_itemsets.iterrows():\n",
    "            print(f\"Items: {set(row['itemsets'])}, Support: {row['support']*100:.2f}%\")\n",
    "    else:\n",
    "        for itemset, support in frequent_itemsets:\n",
    "            print(f\"Items: {set(itemset)}, Support: {support*100:.2f}%\")\n",
    "    \n",
    "    print(\"\\nAssociation Rules:\")\n",
    "    if isinstance(rules, pd.DataFrame):\n",
    "        for _, rule in rules.iterrows():\n",
    "            print(f\"Rule: {set(rule['antecedents'])} -> {set(rule['consequents'])}\")\n",
    "            print(f\"Confidence: {rule['confidence']*100:.2f}%, Support: {rule['support']*100:.2f}%\")\n",
    "            print()\n",
    "    else:\n",
    "        for antecedent, consequent, confidence, support in rules:\n",
    "            print(f\"Rule: {set(antecedent)} -> {set(consequent)}\")\n",
    "            print(f\"Confidence: {confidence*100:.2f}%, Support: {support*100:.2f}%\")\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6ae1591a-6f0e-4c7a-a158-15a1affba1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available stores:\n",
      "1. amazon\n",
      "2. bestbuy\n",
      "3. Costco\n",
      "4. walgreens\n",
      "5. walmart\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the number of the store you want to analyze:  5\n",
      "Enter the minimum support (as a percentage between 0 and 100):  50\n",
      "Enter the minimum confidence (as a percentage between 0 and 100):  70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Brute Force Algorithm...\n",
      "Brute Force Time: 0.4806 seconds\n",
      "\n",
      "Brute Force Results:\n",
      "Frequent Itemsets:\n",
      "\n",
      "Association Rules:\n",
      "\n",
      "Running Apriori Algorithm...\n",
      "Apriori did not find any frequent itemsets.\n",
      "\n",
      "Running FP-Growth Algorithm...\n",
      "FP-Growth did not find any frequent itemsets.\n",
      "\n",
      "Execution Times:\n",
      "Brute Force: 0.4806 seconds\n",
      "Apriori: 0.0000 seconds\n",
      "FP-Growth: 0.0320 seconds\n",
      "\n",
      "The fastest algorithm is: Apriori\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Define available stores and their corresponding files\n",
    "    stores = {\n",
    "        \"1\": (\"amazon\", \"amazon_data.csv\", \"amazon_data.csv\"),\n",
    "        \"2\": (\"bestbuy\", \"best_buy_data.csv\", \"best_buy_data.csv\"),\n",
    "        \"3\": (\"Costco\", \"Costco_Transaction.csv.csv\", \"Costco_Transaction.csv.csv\"),\n",
    "        \"4\": (\"walgreens\", \"walgreens_Transaction.csv.csv\", \"walgreens_Transaction.csv.csv\"),\n",
    "        \"5\": (\"walmart\", \"walmart_data.csv\", \"walmart_data.csv\")\n",
    "    }\n",
    "    \n",
    "    print(\"\\nAvailable stores:\")\n",
    "    for key, (store_name, _, _) in stores.items():\n",
    "        print(f\"{key}. {store_name}\")\n",
    "\n",
    "    # Get user input for store selection.\n",
    "    while True:\n",
    "        choice = input(\"Enter the number of the store you want to analyze: \")\n",
    "        if choice in stores:\n",
    "            store_name, transaction_file, itemset_file = stores[choice]\n",
    "            break\n",
    "        else:\n",
    "            print(\"Invalid choice. Please enter a number between 1 and 5.\")\n",
    "\n",
    "    # Read and prepare transaction data.\n",
    "    try:\n",
    "        transactions = read_csv_and_prepare_transactions(transaction_file, itemset_file)\n",
    "        if not transactions:\n",
    "            print(\"No valid transactions found. Please check your CSV files.\")\n",
    "            return\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading the CSV files: {e}\")\n",
    "        print(\"Please ensure that the CSV files are properly formatted.\")\n",
    "        return\n",
    "\n",
    "# Get user input for minimum support and minimum confidence.\n",
    "    while True:\n",
    "        try:\n",
    "            min_support = float(input(\"Enter the minimum support (as a percentage between 0 and 100): \"))\n",
    "            if 0 <= min_support <= 100:\n",
    "                min_support /= 100  # Convert to decimal\n",
    "                break\n",
    "            else:\n",
    "                print(\"Please enter a value between 0 and 100.\")\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter a number.\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            min_confidence = float(input(\"Enter the minimum confidence (as a percentage between 0 and 100): \"))\n",
    "            if 0 <= min_confidence <= 100:\n",
    "                min_confidence /= 100  # Convert to decimal\n",
    "                break\n",
    "            else:\n",
    "                print(\"Please enter a value between 0 and 100.\")\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter a number.\")\n",
    "\n",
    "    brute_time, apriori_time, fpgrowth_time = run_all_algorithms(transactions, min_support, min_confidence)\n",
    "\n",
    "    print(f\"\\nExecution Times:\")\n",
    "    print(f\"Brute Force: {brute_time:.4f} seconds\")\n",
    "    print(f\"Apriori: {apriori_time:.4f} seconds\")\n",
    "    print(f\"FP-Growth: {fpgrowth_time:.4f} seconds\")\n",
    "\n",
    "    # Print the fastest algorithm.\n",
    "    fastest_algorithm = min((brute_time, 'Brute Force'), (apriori_time, 'Apriori'), (fpgrowth_time, 'FP-Growth'))[1]\n",
    "    print(f\"\\nThe fastest algorithm is: {fastest_algorithm}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871589f5-e3e8-4cf2-8076-1691539e7bda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09279e6-c543-4f86-8f3c-753a6da4694a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1151b2f8-64dc-42a2-9b07-35a43dd92e66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcdbb2e-c266-4808-9380-69a5fecec5ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304353af-3394-4e9e-a962-89682708da79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ce192e-9e9d-40d9-b61f-f8e4c7ca883c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce4990b-ab7f-4852-ba68-8457818cec0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
